(window.webpackJsonp=window.webpackJsonp||[]).push([[35],{320:function(v,_,e){"use strict";e.r(_);var r=e(10),u=Object(r.a)({},(function(){var v=this,_=v._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("p",[v._v("有 10 个文件，每个文件大小为 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求按照 query 的频度排序。")]),v._v(" "),_("p",[v._v("解答思路：")]),v._v(" "),_("ul",[_("li",[v._v("如果 query 的重复度比较大，可以考虑一次性把所有 query 读入内存中处理")]),v._v(" "),_("li",[v._v("如果 query 的重复率不高，那么可用内存不足以容纳所有的 query，这时候就需要采用分治法或其他的方法来解决")])]),v._v(" "),_("p",[_("strong",[v._v("方法1：HashMap 法")])]),v._v(" "),_("p",[v._v("如果 query 重复率高，说明不同 query 总数比较小，可以考虑把所有的 query 都加载到内存中的 HashMap 中。接着就可以按照 query 出现的次数进行排序。")]),v._v(" "),_("p",[_("strong",[v._v("方法2：分治法")])]),v._v(" "),_("p",[v._v("分治法需要根据数据量大小以及可用内存的大小来确定问题划分的规模。")]),v._v(" "),_("p",[v._v("对于这道题，可以顺序遍历 10 个文件中的 query，通过 Hash 函数 "),_("code",[v._v("hash(query) % 10")]),v._v(" 把这些 query 划分到 10 个小文件中。之后对每个小文件使用 HashMap 统计 query 出现次数，根据次数排序并写入到另外一个单独文件中。")]),v._v(" "),_("p",[v._v("接着对所有文件按照 query 的次数进行排序，这里可以使用归并排序（由于无法把所有 query 都读入内存，因此需要使用外排序）。")]),v._v(" "),_("p",[v._v("方法总结：")]),v._v(" "),_("ul",[_("li",[v._v("内存若够，直接读入进行排序")]),v._v(" "),_("li",[v._v("内存不够，先划分为小文件，小文件排好序后，整理使用外排序进行归并")])]),v._v(" "),_("hr"),v._v(" "),_("p",[v._v("原作者：yanglbme")]),v._v(" "),_("p",[v._v("原文链接：https://juejin.cn/post/6844904003998842887")]),v._v(" "),_("p",[v._v("站长略有修改")])])}),[],!1,null,null,null);_.default=u.exports}}]);